%\VignetteIndexEntry{Additive_Models_for_Business_Applications}
\documentclass {article}
\usepackage {maia2}
\SweaveOpts{keep.source=TRUE}
\SweaveOpts{prefix.string=tmp}

\begin{document}

<<echo=false>>=
options(continue=" ")
options(SweaveHooks=list(fig=function()
par(mar=c(5.1, 4.1, 1.1, 2.1))))
@

\mtitle {amba}{0.3.0}{Additive Models for Business Applications}

\mabstract{This vignetted partially introduces the amba package, an R package for using additive models in business with an emphasis on functional estimates and missing values. The current package is not only incomplete, it's in a transitional state. There were some serious flaws in the original design and the current implementation is halfway through the process of correcting those flaws. The sections in this vignette are essentially from the previous version, updated slightly. A completely new vignette is planned for the next revision.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\msec {Implementation Notes}

When fitting linear models, or more generally additive models, one tries to estimate ``effects'', that is, how some change in some explanatory variable influences the expected value of some response. In the earlier versions of this package, those effects were captured by ``term'' objects, environment-based objects following a class hierarchy. In the current version, term object have been replaced by ``contribution'' objects, which are function-based objects.

Consistent with the previous versions, contributions can be linear or smooth, and linear terms can be pure linear, categorical or polynomial.

One feature that's different here, from other's implementations, is that linear contributions may contain multiple parameters each. Another feature that's different, is that there's no overall intercept, and as a general rule, each contribution contains it's own intercept.

The top level algorithm, is designed to be indifferent to the class of contribution, and computes partial residuals in such a way that the models can produce good estimates even when there's a large amount of missing data.

Note, that the changes to the package have introduced some new problems. These should be fixed in the next revision.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\msec {Backfitting with Missing Explanatory Values}

The author finds the idea of throwing away entire observations when one or two values are missing, somewhat barbaric. Here we present a simple solution (which is a natural extension term objects).

One way to think of residuals, is as some vector of values. If we start with the response values and subtract the overall mean, we get values with relatively high variance. If we then subtract the fitted values for the first term, the variance decreases. If we repeat for each term, the variance gradually decreases, until we are left with values with relatively low variance. In the ideal case, the residuals would have zero variance.

If we apply certain special conditions, then it is possible to only subtract a fitted value, where the corresponding explanatory value is valid (i.e. not missing). Where it is not valid, we just skip that subtraction operation (i.e. for that particular observation, the variance is not reduced as much). For this to work, each explanatory variable's partial residuals for each fit (not just the final fit) must be zero-centered. For smoothers this isn't a big issue, however conventional linear terms often do not satisfy this zero-centered condition. Noting the centering condition applies to partial residuals in relation to an explanatory variable (not in relation to a parameter) and each explanatory may have multiple parameters associated with it. For our linear terms to satisfy it, we require extra parameters. Categorical terms require one parameter for each level, and polynomial terms, their own intercepts. 

This produces overall residuals. We can produce partial residuals by adding a term's fitted values. If that particular term has missing values then the corresponding partial residuals will be invalid. However we still get valid partial residuals where other terms have missing values.

Note that we still require valid responses. Plus there are some issues with interactions which are still being explored. For implementation purposes we regard a numeric value as invalid if it is one of \{NA, NaN, Inf, -Inf\} and a factor as invalid if it is NA.

We could write standard residuals for an additive model as:
\begin {eqnarray*}
	r_i &=& y_i - \hat \eta_i \\
	&=& y_i - \left( \hat \theta + \sum _ {\forall t} \hat {\mathrm {f}} _{[t][i]} \right)
\end {eqnarray*}
Where
\begin {itemize}
	\item [$y_i$] is the ith response value.
	\item [$\hat \theta$] is the overall intercept.
	\item [$\hat \eta_i$] is the ith overall fitted value.
	\item [$r_i$] is the ith overall residual.
	\item [$\forall t$] means that we will sum over all terms.
	\item [$\hat {\mathrm {f}} _{[t][i]}$] is the ith fitted value for term t.
\end {itemize}

Standard partial residuals are achieved by merely by either excluding a particular term, or by adding a term's fitted values to the residuals above:
\[	r^*_{[t^*][i]} = r_i + \hat {\mathrm {f}} _{[t^*][i]}
\]
Where
\begin {itemize}
	\item [$t^*$] is a term, for which we are computing partial residuals.
	\item [$r^*_{[t^*][i]}$] is the ith partial residual for term t.
\end {itemize}

Achieving our overall residuals is trivial, we just modify the summation condition so that we only include valid values. Here we are making an assumption that invalid explanatory value results in an invalid fitted value.
\[	r_i =  y_i - \left( \hat \theta + \sum _ {\forall t; \hat {\mathrm {f}} _{[t][i]} \in \mathbb {V} } \hat {\mathrm {f}} _{[t][i]} \right)
\]

Where $\mathbb {V}$ indicates a valid number as described above. We achieve partial residuals using the same formula for standard partial residuals.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\msec {Example}

Here we are going to use a made up dataset to demonstrate some of the things discussed so far. This dataset is pretty bad, and may be replaced in future versions of this package. The examples here a purely to demonstrate how to use the package, they are not intended to be ``good'' models. First we need load the packages and the data.
<<>>=
library (amba)
#may be changed...
d = datafile ("amba", "sample", TRUE)
@

Here d represents a data.frame. A preview of the data.frame shows that it's a bit messy.
<<>>=
d [1:10,]
@

The last part of the preview output is information on the number of valid realisations. Note that there are only two complete realisations. We are only going to use four of the explanatories, so now we have five complete realisations.
<<>>=
d [1:10,c (1:3, 6)]
@

We create terms using constructors, re-iterating the earlier point, in general there is one term to one variable.
<<>>=
t1 = categorical (g1)
t2 = categorical (g2)
t3 = linear (x1)
t4 = linear (x4)
@

We can fit a term separately either by specifying the response as the second argument in the constructor, or by using the fit command. It is not necessary to do an explicit assignment. Terms are environments and the fit command will adjust the estimate object within the term. Functions summary and plot act as expected, except that the summary output is currently a mess and that a response (or partial residuals) are often required as an argument.
<<>>=
fit (t1, y)
summary (t1, y)
@

\begin {center}
<<fig=true>>=
plot (t1)
@
<<fig=true>>=
plot (t1, y)
@
<<fig=true>>=
plot (t1, y, index=TRUE)
@
\end {center}

We can create a MMBA model, using the mmba function. Here the response is fit onto each term, ignoring the other terms. However, first we need to create a termlist object. Noting we can do both in one step if we want. It is also possible to plot the termlist object using the pairs function. We get something based on R's standard pairs plot, the main difference is that categorical variables are jittered.
<<>>=
ts = t1 + t2 + t3 + t4
m = mmba (y, ts)
@

\begin {center}
<<fig=true>>=
plot (m)
@
<<fig=true>>=
pairs (ts)
@
\end {center}

We create an AMBA model basically the same, except using the amba function.
<<>>=
m = amba (y, t1 + t4)
@
%summary (m)

\begin {center}
<<fig=true>>=
plot (m)
@
\end {center}

We can can try a polynomial instead of a regular linear term.
<<>>=
t4 = polynomial (x4, degree=2)
m = amba (y, t1 + t4)
@

\begin {center}
<<fig=true>>=
plot (m)
@
\end {center}

Or create a semiparametric model using a smooth term.
<<>>=
<<>>=
t4 = smooth (x4, smoothness=0.9)
m = amba (y, t1 + t4)
@

\begin {center}
<<fig=true>>=
plot (m)
@
\end {center}

Sometimes we just want to plot one of the terms from the AMBA model.
\begin {center}
<<fig=true>>=
plot (m, 2)
@
\end {center}

We can also get summary output for a single term, noting this uses the partial residuals, not the response itself. We can do the same thing (with some more work) by extracting the partial residuals and using the summary method for the term.
<<>>=
summary (m, 2)
summary (t4, residuals (m, 2))
@

\end{document}






